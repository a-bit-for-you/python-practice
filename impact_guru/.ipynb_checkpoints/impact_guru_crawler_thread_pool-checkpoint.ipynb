{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process Started ...\n",
      "\n",
      "Processing finished in 191.13575172424316 seconds.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "import pymongo\n",
    "import concurrent.futures\n",
    "\n",
    "# time\n",
    "start_time = time.time()\n",
    "\n",
    "print(\"Process Started ...\\n\")\n",
    "\n",
    "# MongoDb Connection\n",
    "mongo_client = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "fundraisers_db = mongo_client[\"fundraisers_db\"]\n",
    "fundraisers_col = fundraisers_db['fundraisers_col']\n",
    "\n",
    "# Free Anonymous proxies taken from https://www.sslproxies.org/\n",
    "# We can use paid version, so the proxy won't expire.\n",
    "\n",
    "proxy_list = ['http://20.97.28.47',  # USA\n",
    "              'http://134.73.254.21',  # China\n",
    "              'http://128.199.214.87',  # Singapore \n",
    "              'http://51.210.219.37',  # France\n",
    "              'http://114.6.227.28',  # Indonesia\n",
    "              'http://27.113.208.74',  # Japan\n",
    "              'http://160.19.232.85',  # South Africa\n",
    "              'http://114.32.84.229',  # Taiwan\n",
    "              'http://79.143.87.136',  # UK\n",
    "              'http://189.113.217.35']  # Brazil\n",
    "\n",
    "\n",
    "# scrape function\n",
    "def scrape(regex, data):\n",
    "\n",
    "    elem = re.search(regex, str(data), re.S)\n",
    "    if elem: return elem.group(1).strip()\n",
    "    return ''\n",
    "\n",
    "\n",
    "# remove html tags from text\n",
    "def strip_html(text):\n",
    "    if text: return re.sub('<.*?>|&nbsp;', '', text, flags=re.S).strip()\n",
    "    return ''\n",
    "\n",
    "\n",
    "# get random proxy\n",
    "def get_proxies(proxy_list):\n",
    "    return {'http': random.choice(proxy_list)}\n",
    "\n",
    "\n",
    "def crawl(i):\n",
    "    \n",
    "    # Category id\n",
    "    cat_id = scrape('data-category=\"(.*?)\"', i)\n",
    "    \n",
    "    # Category name\n",
    "    cat_name = scrape('class=\"tl-p\">(.*?)<', i)\n",
    "    \n",
    "    page_no = 1\n",
    "    \n",
    "    # iterating through pages\n",
    "    while True:\n",
    "        \n",
    "        # Page url\n",
    "        page_url = f'https://www.impactguru.com/fundraisers?category_id={cat_id}&page={page_no}'\n",
    "        \n",
    "        # Fetching page url\n",
    "        page = requests.get(page_url, proxies=get_proxies(proxy_list), headers=headers, timeout=60).text\n",
    "        \n",
    "        # break at last page\n",
    "        if 'class=\"card-h-text\">' not in page:\n",
    "            break\n",
    "            \n",
    "        page_no += 1\n",
    "        \n",
    "        # iterating through fundraiser urls\n",
    "        for j in page.split('box-shadow\">')[1:]:\n",
    "            \n",
    "            fundraiser_url = scrape('href=\"(.*?)\"', j)\n",
    "            \n",
    "            # Fetching fundraiser url\n",
    "            fundraiser_page = requests.get(fundraiser_url, proxies=get_proxies(proxy_list), headers=headers, timeout=60).text\n",
    "            \n",
    "            # Title\n",
    "            title = scrape('\"campaignTitle\">(.*?)<', fundraiser_page)\n",
    "            \n",
    "            # Campaigner Details\n",
    "            campaigner_details = scrape('Campaigner\\s*Details</h5>.*?class=\"description\">(.*?)<a', fundraiser_page)\n",
    "            campaigner_details = strip_html(campaigner_details)\n",
    "            \n",
    "            # Beneficiary details\n",
    "            beneficiary_details = scrape('Beneficiary\\s*Details</h5>.*?class=\"description\">(.*?)</div>\\s*</div>', fundraiser_page)            \n",
    "            beneficiary_details = strip_html(beneficiary_details)\n",
    "            \n",
    "            # Campaigner location\n",
    "            campaigner_location = scrape('fa-map-marker-alt mr-1\"></i>(.*?)<', fundraiser_page)\n",
    "            \n",
    "            # Raised amount\n",
    "            raised_amount = scrape('custom-raisedAmount\">(.*?)<', fundraiser_page)\n",
    "            \n",
    "            # Required amount\n",
    "            required_amount = scrape('class=\"box-stick__color-light\">of(.*?)<', fundraiser_page)\n",
    "            \n",
    "            # Donors\n",
    "            donors = scrape('custom-donors\".*?>(.*?)<', fundraiser_page)\n",
    "            \n",
    "            # Story\n",
    "            story = scrape('id=\"description\">(.*?)<div\\s*class=\"campaign-story', fundraiser_page)\n",
    "            story = strip_html(story)\n",
    "            \n",
    "            # Bank account details\n",
    "            bank_acc_details = scrape('Donate via Bank Transfer</h4>.*?<li>-(.*?)<li>For\\s*UPI', fundraiser_page)\n",
    "            bank_acc_details = strip_html(bank_acc_details)\n",
    "            \n",
    "            # UPI Id\n",
    "            upi_id = scrape('upi://pay\\?pa=(.*?)&', fundraiser_page)\n",
    "            \n",
    "            # Storing the scraped information in dictionary\n",
    "            fund_raiser_dic = {\n",
    "                'title': title,\n",
    "                'fundraiser_url': fundraiser_url,\n",
    "                'category': cat_name,\n",
    "                'campaigner_details': campaigner_details,\n",
    "                'beneficiary_details': beneficiary_details,\n",
    "                'campaigner_location': campaigner_location,\n",
    "                'raised_amount': raised_amount,\n",
    "                'required_amount': required_amount,\n",
    "                'donors': donors,\n",
    "                'story': story,\n",
    "                'bank_acc_details': bank_acc_details,\n",
    "                'upi_id': upi_id\n",
    "            }\n",
    "            \n",
    "            # inserting data\n",
    "            fundraisers_col.insert_one(fund_raiser_dic)\n",
    "        \n",
    "\n",
    "fundraisers_url = 'https://www.impactguru.com/fundraisers'\n",
    "\n",
    "headers = {\n",
    "            'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36'\n",
    "    }\n",
    "\n",
    "# fetching fundraiser url\n",
    "response = requests.get(fundraisers_url, proxies=get_proxies(proxy_list), headers=headers, timeout=60).text\n",
    "\n",
    "threads = []\n",
    "\n",
    "categories = re.split('<a\\s*class=\"nav-link\\s*category-nav-link', response)[1:]\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    executor.map(crawl, categories)\n",
    "    \n",
    "    \n",
    "print(f'Processing finished in {time.time() - start_time} seconds.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
